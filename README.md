# Optimisation-and-the-Gradient-Descent-Algorithm

Gradient descent is an optimization algorithm that’s used when training a machine learning model. It’s based on a convex function and tweaks its parameters iteratively to minimize a given function to its local minimum.
To start by defining the initial parameter’s values and from there the gradient descent algorithm uses calculus to iteratively adjust the values so they minimize the given cost-function. 
